{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESUrb0gGR6TQ"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nonrjto2UmGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d756304-9ab4-4701-c29d-7b9d51a401eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjdFJfERbevh",
        "outputId": "add788b1-cb48-49df-fb3d-eae69d615259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import time\n",
        "!add-apt-repository --yes ppa:deadsnakes/ppa\n",
        "!apt-get update\n",
        "!apt-get install python3.6\n",
        "!apt-get install python3.6-dev\n",
        "\n",
        "!wget https://bootstrap.pypa.io/get-pip.py && python3.6 get-pip.py\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path[2] = '/usr/lib/python36.zip'\n",
        "sys.path[3] = '/usr/lib/python3.6'\n",
        "sys.path[4] = '/usr/lib/python3.6/lib-dynload'\n",
        "sys.path[5] = '/usr/local/lib/python3.6/dist-packages'\n",
        "sys.path[7] = '/usr/local/lib/python3.6/dist-packages/IPython/extensions'\n",
        "\n",
        "!pip install tensorflow==1.12\n",
        "\n",
        "clear_output()\n",
        "time.sleep(1)\n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "MS0-_Nad_1Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.12\n",
        "!pip install keras==2.2.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtObwRpxcSpE",
        "outputId": "7dca289b-34d7-453e-ed6a-1754b304e11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.12 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.12\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras==2.2.5) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras==2.2.5) (1.13.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras==2.2.5) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras==2.2.5) (6.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==2.2.5) (3.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from keras==2.2.5) (1.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZXE_6i8R9VH"
      },
      "source": [
        "- Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkjzR-DaOGPU",
        "outputId": "a18be8c6-38e3-4417-d733-2c5f39cde8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nfp\n",
            "  Downloading nfp-0.3.12-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nfp) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nfp) (4.66.6)\n",
            "Requirement already satisfied: networkx>2.0 in /usr/local/lib/python3.10/dist-packages (from nfp) (3.4.2)\n",
            "Downloading nfp-0.3.12-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: nfp\n",
            "Successfully installed nfp-0.3.12\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (11.0.0)\n",
            "Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2022.9.5\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.3\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "#from tensorflow import set_random_seed\n",
        "#set_random_seed(2)\n",
        "\n",
        "\n",
        "#from nfp.preprocessing import MolPreprocessor, GraphSequence\n",
        "\n",
        "import gzip\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "# Define Keras model\n",
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
        "\n",
        "from keras.layers import (Input, Embedding, Dense, BatchNormalization, Dropout,\n",
        "                                 Concatenate, Multiply, Add)\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "#from nfp.layers import (MessageLayer, GRUStep, Squeeze, EdgeNetwork,\n",
        " #                              ReduceAtomToMol, ReduceBondToAtom,\n",
        "  #                             GatherAtomToBond, ReduceAtomToPro)\n",
        "#from nfp.models import GraphModel\n",
        "import argparse\n",
        "!pip install nfp\n",
        "\n",
        "from nfp.preprocessing import features\n",
        "from nfp.preprocessing import Tokenizer\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "!pip install rdkit-pypi\n",
        "!pip install --upgrade rdkit-pypi pandas\n",
        "\n",
        "from rdkit import Chem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPvAXXmTR_Xt"
      },
      "source": [
        "- Getting classes from the CASCADE paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MgA2m0WQIQ2"
      },
      "outputs": [],
      "source": [
        "def atomic_number_tokenizer(atom):\n",
        "    return atom.GetAtomicNum()\n",
        "def Mol_iter(df):\n",
        "    for index,r in df.iterrows():\n",
        "        yield(r['Mol'], r['atom_index'])\n",
        "\n",
        "class SmilesPreprocessor(object):\n",
        "    \"\"\" Given a list of SMILES strings, encode these molecules as atom and\n",
        "    connectivity feature matricies.\n",
        "\n",
        "    Example:\n",
        "    >>> preprocessor = SmilesPreprocessor(explicit_hs=False)\n",
        "    >>> inputs = preprocessor.fit(data.smiles)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, explicit_hs=True, atom_features=None, bond_features=None):\n",
        "        \"\"\"\n",
        "\n",
        "        explicit_hs : bool\n",
        "            whether to tell RDkit to add H's to a molecule.\n",
        "        atom_features : function\n",
        "            A function applied to an rdkit.Atom that returns some\n",
        "            representation (i.e., string, integer) for the Tokenizer class.\n",
        "        bond_features : function\n",
        "            A function applied to an rdkit Bond to return some description.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.atom_tokenizer = Tokenizer()\n",
        "        self.bond_tokenizer = Tokenizer()\n",
        "        self.explicit_hs = explicit_hs\n",
        "\n",
        "        if atom_features is None:\n",
        "            atom_features = features.atom_features_v1\n",
        "\n",
        "        if bond_features is None:\n",
        "            bond_features = features.bond_features_v1\n",
        "\n",
        "        self.atom_features = atom_features\n",
        "        self.bond_features = bond_features\n",
        "\n",
        "\n",
        "    def fit(self, smiles_iterator):\n",
        "        \"\"\" Fit an iterator of SMILES strings, creating new atom and bond\n",
        "        tokens for unseen molecules. Returns a dictionary with 'atom' and\n",
        "        'connectivity' entries \"\"\"\n",
        "        return list(self.preprocess(smiles_iterator, train=True))\n",
        "\n",
        "\n",
        "    def predict(self, smiles_iterator):\n",
        "        \"\"\" Uses previously determined atom and bond tokens to convert a SMILES\n",
        "        iterator into 'atom' and 'connectivity' matrices. Ensures that atom and\n",
        "        bond classes commute with previously determined results. \"\"\"\n",
        "        return list(self.preprocess(smiles_iterator, train=False))\n",
        "\n",
        "\n",
        "    def preprocess(self, smiles_iterator, train=True):\n",
        "\n",
        "        self.atom_tokenizer.train = train\n",
        "        self.bond_tokenizer.train = train\n",
        "\n",
        "        for smiles in tqdm(smiles_iterator):\n",
        "            yield self.construct_feature_matrices(smiles)\n",
        "\n",
        "\n",
        "    @property\n",
        "    def atom_classes(self):\n",
        "        \"\"\" The number of atom types found (includes the 0 null-atom type) \"\"\"\n",
        "        return self.atom_tokenizer.num_classes + 1\n",
        "\n",
        "\n",
        "    @property\n",
        "    def bond_classes(self):\n",
        "        \"\"\" The number of bond types found (includes the 0 null-bond type) \"\"\"\n",
        "        return self.bond_tokenizer.num_classes + 1\n",
        "\n",
        "\n",
        "    def construct_feature_matrices(self, smiles):\n",
        "        \"\"\" construct a molecule from the given smiles string and return atom\n",
        "        and bond classes.\n",
        "\n",
        "        Returns\n",
        "        dict with entries\n",
        "        'n_atom' : number of atoms in the molecule\n",
        "        'n_bond' : number of bonds in the molecule\n",
        "        'atom' : (n_atom,) length list of atom classes\n",
        "        'bond' : (n_bond,) list of bond classes\n",
        "        'connectivity' : (n_bond, 2) array of source atom, target atom pairs.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        mol = MolFromSmiles(smiles)\n",
        "        if self.explicit_hs:\n",
        "            mol = AddHs(mol)\n",
        "\n",
        "        n_atom = len(mol.GetAtoms())\n",
        "        n_bond = 2 * len(mol.GetBonds())\n",
        "\n",
        "        # If its an isolated atom, add a self-link\n",
        "        if n_bond == 0:\n",
        "            n_bond = 1\n",
        "\n",
        "        atom_feature_matrix = np.zeros(n_atom, dtype='int')\n",
        "        bond_feature_matrix = np.zeros(n_bond, dtype='int')\n",
        "        connectivity = np.zeros((n_bond, 2), dtype='int')\n",
        "\n",
        "        bond_index = 0\n",
        "\n",
        "        atom_seq = mol.GetAtoms()\n",
        "        atoms = [atom_seq[i] for i in range(n_atom)]\n",
        "\n",
        "        for n, atom in enumerate(atoms):\n",
        "\n",
        "            # Atom Classes\n",
        "            atom_feature_matrix[n] = self.atom_tokenizer(\n",
        "                self.atom_features(atom))\n",
        "\n",
        "            start_index = atom.GetIdx()\n",
        "\n",
        "            for bond in atom.GetBonds():\n",
        "                # Is the bond pointing at the target atom\n",
        "                rev = bond.GetBeginAtomIdx() != start_index\n",
        "\n",
        "                # Bond Classes\n",
        "                bond_feature_matrix[n] = self.bond_tokenizer(\n",
        "                    self.bond_features(bond, flipped=rev))\n",
        "\n",
        "                # Connectivity\n",
        "                if not rev:  # Original direction\n",
        "                    connectivity[bond_index, 0] = bond.GetBeginAtomIdx()\n",
        "                    connectivity[bond_index, 1] = bond.GetEndAtomIdx()\n",
        "\n",
        "                else:  # Reversed\n",
        "                    connectivity[bond_index, 0] = bond.GetEndAtomIdx()\n",
        "                    connectivity[bond_index, 1] = bond.GetBeginAtomIdx()\n",
        "\n",
        "                bond_index += 1\n",
        "\n",
        "\n",
        "        return {\n",
        "            'n_atom': n_atom,\n",
        "            'n_bond': n_bond,\n",
        "            'atom': atom_feature_matrix,\n",
        "            'bond': bond_feature_matrix,\n",
        "            'connectivity': connectivity,\n",
        "        }\n",
        "\n",
        "\n",
        "class ConnectivityAPreprocessor(object):\n",
        "    \"\"\" Given a list of SMILES strings, encode these molecules as atom and\n",
        "    connectivity feature matricies.\n",
        "\n",
        "    Example:\n",
        "    >>> preprocessor = SmilesPreprocessor(explicit_hs=False)\n",
        "    >>> inputs = preprocessor.fit(data.smiles)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, explicit_hs=True, atom_features=None, bond_features=None):\n",
        "        \"\"\"\n",
        "\n",
        "        explicit_hs : bool\n",
        "            whether to tell RDkit to add H's to a molecule.\n",
        "        atom_features : function\n",
        "            A function applied to an rdkit.Atom that returns some\n",
        "            representation (i.e., string, integer) for the Tokenizer class.\n",
        "        bond_features : function\n",
        "            A function applied to an rdkit Bond to return some description.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.atom_tokenizer = Tokenizer()\n",
        "        self.bond_tokenizer = Tokenizer()\n",
        "        self.explicit_hs = explicit_hs\n",
        "\n",
        "        if atom_features is None:\n",
        "            atom_features = features.atom_features_v1\n",
        "\n",
        "        if bond_features is None:\n",
        "            bond_features = features.bond_features_v1\n",
        "\n",
        "        self.atom_features = atom_features\n",
        "        self.bond_features = bond_features\n",
        "\n",
        "\n",
        "    def fit(self, smiles_iterator):\n",
        "        \"\"\" Fit an iterator of SMILES strings, creating new atom and bond\n",
        "        tokens for unseen molecules. Returns a dictionary with 'atom' and\n",
        "        'connectivity' entries \"\"\"\n",
        "        return list(self.preprocess(smiles_iterator, train=True))\n",
        "\n",
        "\n",
        "    def predict(self, smiles_iterator):\n",
        "        \"\"\" Uses previously determined atom and bond tokens to convert a SMILES\n",
        "        iterator into 'atom' and 'connectivity' matrices. Ensures that atom and\n",
        "        bond classes commute with previously determined results. \"\"\"\n",
        "        return list(self.preprocess(smiles_iterator, train=False))\n",
        "\n",
        "\n",
        "    def preprocess(self, smiles_iterator, train=True):\n",
        "\n",
        "        self.atom_tokenizer.train = train\n",
        "        self.bond_tokenizer.train = train\n",
        "\n",
        "        for smiles in tqdm(smiles_iterator):\n",
        "            yield self.construct_feature_matrices(smiles)\n",
        "\n",
        "\n",
        "    @property\n",
        "    def atom_classes(self):\n",
        "        \"\"\" The number of atom types found (includes the 0 null-atom type) \"\"\"\n",
        "        return self.atom_tokenizer.num_classes + 1\n",
        "\n",
        "\n",
        "    @property\n",
        "    def bond_classes(self):\n",
        "        \"\"\" The number of bond types found (includes the 0 null-bond type) \"\"\"\n",
        "        return self.bond_tokenizer.num_classes + 1\n",
        "\n",
        "\n",
        "    def construct_feature_matrices(self, smiles):\n",
        "        \"\"\" construct a molecule from the given smiles string and return atom\n",
        "        and bond classes.\n",
        "\n",
        "        Returns\n",
        "        dict with entries\n",
        "        'n_atom' : number of atoms in the molecule\n",
        "        'n_bond' : number of bonds in the molecule\n",
        "        'atom' : (n_atom,) length list of atom classes\n",
        "        'bond' : (n_bond,) list of bond classes\n",
        "        'connectivity' : (n_bond, 2) array of source atom, target atom pairs.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        mol = MolFromSmiles(smiles)\n",
        "        if self.explicit_hs:\n",
        "            mol = AddHs(mol)\n",
        "\n",
        "        n_atom = len(mol.GetAtoms())\n",
        "        n_bond = 2 * len(mol.GetBonds())\n",
        "\n",
        "        # If its an isolated atom, add a self-link\n",
        "        if n_bond == 0:\n",
        "            n_bond = 1\n",
        "\n",
        "        atom_feature_matrix = np.zeros(n_atom, dtype='int')\n",
        "        bond_feature_matrix = np.zeros(n_bond, dtype='int')\n",
        "        connectivity = np.zeros((n_bond, 2), dtype='int')\n",
        "\n",
        "        bond_index = 0\n",
        "\n",
        "        atom_seq = mol.GetAtoms()\n",
        "        atoms = [atom_seq[i] for i in range(n_atom)]\n",
        "\n",
        "        for n, atom in enumerate(atoms):\n",
        "\n",
        "            # Atom Classes\n",
        "            atom_feature_matrix[n] = self.atom_tokenizer(\n",
        "                self.atom_features(atom))\n",
        "\n",
        "            start_index = atom.GetIdx()\n",
        "\n",
        "            for bond in atom.GetBonds():\n",
        "                # Is the bond pointing at the target atom\n",
        "                rev = bond.GetBeginAtomIdx() != start_index\n",
        "\n",
        "                # Bond Classes\n",
        "                bond_feature_matrix[n] = self.bond_tokenizer(\n",
        "                    self.bond_features(bond, flipped=rev))\n",
        "\n",
        "                # Connectivity\n",
        "                if not rev:  # Original direction\n",
        "                    connectivity[bond_index, 0] = bond.GetBeginAtomIdx()\n",
        "                    connectivity[bond_index, 1] = bond.GetEndAtomIdx()\n",
        "\n",
        "                else:  # Reversed\n",
        "                    connectivity[bond_index, 0] = bond.GetEndAtomIdx()\n",
        "                    connectivity[bond_index, 1] = bond.GetBeginAtomIdx()\n",
        "\n",
        "                bond_index += 1\n",
        "\n",
        "        return {\n",
        "            'n_atom': n_atom,\n",
        "            'n_bond': n_bond,\n",
        "            'atom': atom_feature_matrix,\n",
        "            'bond': bond_feature_matrix,\n",
        "            'connectivity': connectivity,\n",
        "        }\n",
        "\n",
        "\n",
        "class MolPreprocessor(SmilesPreprocessor):\n",
        "    \"\"\" I should refactor this into a base class and separate\n",
        "    SmilesPreprocessor classes. But the idea is that we only need to redefine\n",
        "    the `construct_feature_matrices` method to have a working preprocessor that\n",
        "    handles 3D structures.\n",
        "\n",
        "    We'll pass an iterator of mol objects instead of SMILES strings this time,\n",
        "    though.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_neighbors, cutoff, **kwargs):\n",
        "        \"\"\" A preprocessor class that also returns distances between\n",
        "        neighboring atoms. Adds edges for non-bonded atoms to include a maximum\n",
        "        of n_neighbors around each atom \"\"\"\n",
        "\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.cutoff = cutoff\n",
        "        super(MolPreprocessor, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def construct_feature_matrices(self, mol):\n",
        "        \"\"\" Given an rdkit mol, return atom feature matrices, bond feature\n",
        "        matrices, and connectivity matrices.\n",
        "\n",
        "        Returns\n",
        "        dict with entries\n",
        "        'n_atom' : number of atoms in the molecule\n",
        "        'n_bond' : number of edges (likely n_atom * n_neighbors)\n",
        "        'atom' : (n_atom,) length list of atom classes\n",
        "        'bond' : (n_bond,) list of bond classes. 0 for no bond\n",
        "        'distance' : (n_bond,) list of bond distances\n",
        "        'connectivity' : (n_bond, 2) array of source atom, target atom pairs.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        n_atom = len(mol.GetAtoms())\n",
        "\n",
        "        # n_bond is actually the number of atom-atom pairs, so this is defined\n",
        "        # by the number of neighbors for each atom.\n",
        "        #if there is cutoff,\n",
        "        distance_matrix = Chem.Get3DDistanceMatrix(mol)\n",
        "\n",
        "        if self.n_neighbors <= (n_atom - 1):\n",
        "            n_bond = self.n_neighbors * n_atom\n",
        "        else:\n",
        "            # If there are fewer atoms than n_neighbors, all atoms will be\n",
        "            # connected\n",
        "            n_bond = distance_matrix[(distance_matrix < self.cutoff) & (distance_matrix != 0)].size\n",
        "\n",
        "        if n_bond == 0: n_bond = 1\n",
        "\n",
        "        # Initialize the matrices to be filled in during the following loop.\n",
        "        atom_feature_matrix = np.zeros(n_atom, dtype='int')\n",
        "        bond_feature_matrix = np.zeros(n_bond, dtype='int')\n",
        "        bond_distance_matrix = np.zeros(n_bond, dtype=np.float32)\n",
        "        connectivity = np.zeros((n_bond, 2), dtype='int')\n",
        "\n",
        "        # Hopefully we've filtered out all problem mols by now.\n",
        "        if mol is None:\n",
        "            raise RuntimeError(\"Issue in loading mol\")\n",
        "\n",
        "        # Get a list of the atoms in the molecule.\n",
        "        atom_seq = mol.GetAtoms()\n",
        "        atoms = [atom_seq[i] for i in range(n_atom)]\n",
        "\n",
        "        # Here we loop over each atom, and the inner loop iterates over each\n",
        "        # neighbor of the current atom.\n",
        "        bond_index = 0  # keep track of our current bond.\n",
        "        for n, atom in enumerate(atoms):\n",
        "\n",
        "            # update atom feature matrix\n",
        "            atom_feature_matrix[n] = self.atom_tokenizer(\n",
        "                self.atom_features(atom))\n",
        "\n",
        "            # if n_neighbors is greater than total atoms, then each atom is a\n",
        "            # neighbor.\n",
        "            if (self.n_neighbors + 1) > len(mol.GetAtoms()):\n",
        "                neighbor_end_index = len(mol.GetAtoms())\n",
        "            else:\n",
        "                neighbor_end_index = (self.n_neighbors + 1)\n",
        "\n",
        "            distance_atom = distance_matrix[n, :]\n",
        "            cutoff_end_index = distance_atom[distance_atom < self.cutoff].size\n",
        "\n",
        "            end_index = min(neighbor_end_index, cutoff_end_index)\n",
        "\n",
        "            # Loop over each of the nearest neighbors\n",
        "\n",
        "            neighbor_inds = distance_matrix[n, :].argsort()[1:end_index]\n",
        "            if len(neighbor_inds)==0: neighbor_inds = [n]\n",
        "            for neighbor in neighbor_inds:\n",
        "\n",
        "                # update bond feature matrix\n",
        "                bond = mol.GetBondBetweenAtoms(n, int(neighbor))\n",
        "                if bond is None:\n",
        "                    bond_feature_matrix[bond_index] = 0\n",
        "                else:\n",
        "                    rev = False if bond.GetBeginAtomIdx() == n else True\n",
        "                    bond_feature_matrix[bond_index] = self.bond_tokenizer(\n",
        "                        self.bond_features(bond, flipped=rev))\n",
        "\n",
        "                distance = distance_matrix[n, neighbor]\n",
        "                bond_distance_matrix[bond_index] = distance\n",
        "\n",
        "                # update connectivity matrix\n",
        "                connectivity[bond_index, 0] = n\n",
        "                connectivity[bond_index, 1] = neighbor\n",
        "\n",
        "                bond_index += 1\n",
        "        print(connectivity)\n",
        "\n",
        "        return {\n",
        "            'n_atom': n_atom,\n",
        "            'n_bond': n_bond,\n",
        "            'atom': atom_feature_matrix,\n",
        "            'bond': bond_feature_matrix,\n",
        "            'distance': bond_distance_matrix,\n",
        "            'connectivity': connectivity,\n",
        "        }\n",
        "\n",
        "\n",
        "class MolBPreprocessor(MolPreprocessor):\n",
        "    \"\"\"\n",
        "    This is a subclass of Molpreprocessor that preprocessor molecule with\n",
        "    bond property target\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        \"\"\"\n",
        "        A preprocessor class that also returns bond_target_matrix, besides the bond matrix\n",
        "        returned by MolPreprocessor. The bond_target_matrix is then used as ref to reduce molecule\n",
        "        to bond property\n",
        "        \"\"\"\n",
        "        super(MolBPreprocessor, self).__init__(**kwargs)\n",
        "\n",
        "    def construct_feature_matrices(self, entry):\n",
        "        \"\"\"\n",
        "        Given an entry contining rdkit molecule, bond_index and for the target property,\n",
        "        return atom\n",
        "        feature matrices, bond feature matrices, distance matrices, connectivity matrices and bond\n",
        "        ref matrices.\n",
        "\n",
        "        returns\n",
        "        dict with entries\n",
        "        see MolPreproccessor\n",
        "        'bond_index' : ref array to the bond index\n",
        "        \"\"\"\n",
        "        mol, bond_index_array = entry\n",
        "\n",
        "        n_atom = len(mol.GetAtoms())\n",
        "        n_pro = len(bond_index_array)\n",
        "\n",
        "        # n_bond is actually the number of atom-atom pairs, so this is defined\n",
        "        # by the number of neighbors for each atom.\n",
        "        #if there is cutoff,\n",
        "        distance_matrix = Chem.Get3DDistanceMatrix(mol)\n",
        "\n",
        "        if self.n_neighbors <= (n_atom - 1):\n",
        "            n_bond = self.n_neighbors * n_atom\n",
        "        else:\n",
        "            # If there are fewer atoms than n_neighbors, all atoms will be\n",
        "            # connected\n",
        "            n_bond = distance_matrix[(distance_matrix < self.cutoff) & (distance_matrix != 0)].size\n",
        "\n",
        "        if n_bond == 0: n_bond = 1\n",
        "\n",
        "        # Initialize the matrices to be filled in during the following loop.\n",
        "        atom_feature_matrix = np.zeros(n_atom, dtype='int')\n",
        "        bond_feature_matrix = np.zeros(n_bond, dtype='int')\n",
        "        bond_distance_matrix = np.zeros(n_bond, dtype=np.float32)\n",
        "        bond_index_matrix = np.full(n_bond, -1, dtype='int')\n",
        "        connectivity = np.zeros((n_bond, 2), dtype='int')\n",
        "\n",
        "        # Hopefully we've filtered out all problem mols by now.\n",
        "        if mol is None:\n",
        "            raise RuntimeError(\"Issue in loading mol\")\n",
        "\n",
        "        # Get a list of the atoms in the molecule.\n",
        "        atom_seq = mol.GetAtoms()\n",
        "        atoms = [atom_seq[i] for i in range(n_atom)]\n",
        "\n",
        "        # Here we loop over each atom, and the inner loop iterates over each\n",
        "        # neighbor of the current atom.\n",
        "        bond_index = 0  # keep track of our current bond.\n",
        "        for n, atom in enumerate(atoms):\n",
        "            # update atom feature matrix\n",
        "            atom_feature_matrix[n] = self.atom_tokenizer(\n",
        "                self.atom_features(atom))\n",
        "\n",
        "            # if n_neighbors is greater than total atoms, then each atom is a\n",
        "            # neighbor.\n",
        "            if (self.n_neighbors + 1) > len(mol.GetAtoms()):\n",
        "                neighbor_end_index = len(mol.GetAtoms())\n",
        "            else:\n",
        "                neighbor_end_index = (self.n_neighbors + 1)\n",
        "\n",
        "            distance_atom = distance_matrix[n, :]\n",
        "            cutoff_end_index = distance_atom[distance_atom < self.cutoff].size\n",
        "\n",
        "            end_index = min(neighbor_end_index, cutoff_end_index)\n",
        "\n",
        "            # Loop over each of the nearest neighbors\n",
        "\n",
        "            neighbor_inds = distance_matrix[n, :].argsort()[1:end_index]\n",
        "            if len(neighbor_inds)==0: neighbor_inds = [n]\n",
        "            for neighbor in neighbor_inds:\n",
        "\n",
        "                # update bond feature matrix\n",
        "                bond = mol.GetBondBetweenAtoms(n, int(neighbor))\n",
        "                if bond is None:\n",
        "                    bond_feature_matrix[bond_index] = 0\n",
        "                else:\n",
        "                    rev = False if bond.GetBeginAtomIdx() == n else True\n",
        "                    bond_feature_matrix[bond_index] = self.bond_tokenizer(\n",
        "                        self.bond_features(bond, flipped=rev))\n",
        "                    try:\n",
        "                        bond_index_matrix[bond_index] = bond_index_array.tolist().index(bond.GetIdx())\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                distance = distance_matrix[n, neighbor]\n",
        "                bond_distance_matrix[bond_index] = distance\n",
        "\n",
        "                # update connectivity matrix\n",
        "                connectivity[bond_index, 0] = n\n",
        "                connectivity[bond_index, 1] = neighbor\n",
        "\n",
        "                bond_index += 1\n",
        "        return {\n",
        "            'n_atom': n_atom,\n",
        "            'n_bond': n_bond,\n",
        "            'n_pro': n_pro,\n",
        "            'atom': atom_feature_matrix,\n",
        "            'bond': bond_feature_matrix,\n",
        "            'distance': bond_distance_matrix,\n",
        "            'connectivity': connectivity,\n",
        "            'bond_index': bond_index_matrix,\n",
        "        }\n",
        "\n",
        "class MolAPreprocessor(MolPreprocessor):\n",
        "    \"\"\"\n",
        "    This is a subclass of Molpreprocessor that preprocessor molecule with\n",
        "    bond property target\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        \"\"\"\n",
        "        A preprocessor class that also returns bond_target_matrix, besides the bond matrix\n",
        "        returned by MolPreprocessor. The bond_target_matrix is then used as ref to reduce molecule\n",
        "        to bond property\n",
        "        \"\"\"\n",
        "        super(MolAPreprocessor, self).__init__(**kwargs)\n",
        "\n",
        "    def construct_feature_matrices(self, entry):\n",
        "        \"\"\"\n",
        "        Given an entry contining rdkit molecule, bond_index and for the target property,\n",
        "        return atom\n",
        "        feature matrices, bond feature matrices, distance matrices, connectivity matrices and bond\n",
        "        ref matrices.\n",
        "\n",
        "        returns\n",
        "        dict with entries\n",
        "        see MolPreproccessor\n",
        "        'bond_index' : ref array to the bond index\n",
        "        \"\"\"\n",
        "        mol, atom_index_array = entry\n",
        "\n",
        "        n_atom = len(mol.GetAtoms())\n",
        "        n_pro = len(atom_index_array)\n",
        "\n",
        "        # n_bond is actually the number of atom-atom pairs, so this is defined\n",
        "        # by the number of neighbors for each atom.\n",
        "        #if there is cutoff,\n",
        "        distance_matrix = Chem.Get3DDistanceMatrix(mol)\n",
        "\n",
        "        #if self.n_neighbors <= (n_atom - 1):\n",
        "        #    n_bond = self.n_neighbors * n_atom\n",
        "        #else:\n",
        "            # If there are fewer atoms than n_neighbors, all atoms will be\n",
        "            # connected\n",
        "        n_bond = distance_matrix[(distance_matrix < self.cutoff) & (distance_matrix != 0)].size\n",
        "\n",
        "        if n_bond == 0: n_bond = 1\n",
        "\n",
        "        # Initialize the matrices to be filled in during the following loop.\n",
        "        atom_feature_matrix = np.zeros(n_atom, dtype='int')\n",
        "        bond_feature_matrix = np.zeros(n_bond, dtype='int')\n",
        "        bond_distance_matrix = np.zeros(n_bond, dtype=np.float32)\n",
        "        atom_index_matrix = np.full(n_atom, -1, dtype='int')\n",
        "        connectivity = np.zeros((n_bond, 2), dtype='int')\n",
        "\n",
        "        # Hopefully we've filtered out all problem mols by now.\n",
        "        if mol is None:\n",
        "            raise RuntimeError(\"Issue in loading mol\")\n",
        "\n",
        "        # Get a list of the atoms in the molecule.\n",
        "        atom_seq = mol.GetAtoms()\n",
        "        atoms = [atom_seq[i] for i in range(n_atom)]\n",
        "\n",
        "        # Here we loop over each atom, and the inner loop iterates over each\n",
        "        # neighbor of the current atom.\n",
        "        bond_index = 0  # keep track of our current bond.\n",
        "        for n, atom in enumerate(atoms):\n",
        "            # update atom feature matrix\n",
        "            atom_feature_matrix[n] = self.atom_tokenizer(\n",
        "                self.atom_features(atom))\n",
        "            try:\n",
        "                atom_index_matrix[n] = atom_index_array.tolist().index(atom.GetIdx())\n",
        "            except:\n",
        "                pass\n",
        "            # if n_neighbors is greater than total atoms, then each atom is a\n",
        "            # neighbor.\n",
        "            if (self.n_neighbors + 1) > len(mol.GetAtoms()):\n",
        "                neighbor_end_index = len(mol.GetAtoms())\n",
        "            else:\n",
        "                neighbor_end_index = (self.n_neighbors + 1)\n",
        "\n",
        "            distance_atom = distance_matrix[n, :]\n",
        "            cutoff_end_index = distance_atom[distance_atom < self.cutoff].size\n",
        "\n",
        "            end_index = min(neighbor_end_index, cutoff_end_index)\n",
        "\n",
        "            # Loop over each of the nearest neighbors\n",
        "\n",
        "            neighbor_inds = distance_matrix[n, :].argsort()[1:end_index]\n",
        "            if len(neighbor_inds)==0: neighbor_inds = [n]\n",
        "            for neighbor in neighbor_inds:\n",
        "\n",
        "                # update bond feature matrix\n",
        "                bond = mol.GetBondBetweenAtoms(n, int(neighbor))\n",
        "                try:\n",
        "                    if bond is None:\n",
        "                        bond_feature_matrix[bond_index] = 0\n",
        "                    else:\n",
        "                        rev = False if bond.GetBeginAtomIdx() == n else True\n",
        "                        bond_feature_matrix[bond_index] = self.bond_tokenizer(\n",
        "                            self.bond_features(bond, flipped=rev))\n",
        "                except:\n",
        "                    print('AAAAAAAAAAAAAAA')\n",
        "                    print(mol.GetProp('_Name'))\n",
        "                    print(mol.GetProp('ConfId'))\n",
        "\n",
        "                distance = distance_matrix[n, neighbor]\n",
        "                bond_distance_matrix[bond_index] = distance\n",
        "\n",
        "                # update connectivity matrix\n",
        "                connectivity[bond_index, 0] = n\n",
        "                connectivity[bond_index, 1] = neighbor\n",
        "\n",
        "                bond_index += 1\n",
        "        return {\n",
        "            'n_atom': n_atom,\n",
        "            'n_bond': n_bond,\n",
        "            'n_pro': n_pro,\n",
        "            'atom': atom_feature_matrix,\n",
        "            'bond': bond_feature_matrix,\n",
        "            'distance': bond_distance_matrix,\n",
        "            'connectivity': connectivity,\n",
        "            'atom_index': atom_index_matrix,\n",
        "        }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNLSbWHnUPbl"
      },
      "source": [
        "# More Class imports from the paper (There's a lot of code review to do D:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWPFyuKXQ6DR"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras import Layer\n",
        "from keras import activations\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "class GraphModel(Model):\n",
        "    \"\"\" This is a simple modification of the Keras `Model` class to avoid\n",
        "    checking each input for a consistent batch_size dimension. Should work as\n",
        "    of keras-team/keras#11548.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def _standardize_user_data(self, *args, **kwargs):\n",
        "        kwargs['check_array_lengths'] = False\n",
        "        return super(GraphModel, self)._standardize_user_data(*args, **kwargs)\n",
        "class MessageLayer(Layer):\n",
        "    \"\"\" Implements the matrix multiplication message functions from Gilmer\n",
        "    2017. This could probably be implemented as a series of other layers, but\n",
        "    this is more convenient.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout=0., reducer=None, **kwargs):\n",
        "        \"\"\"\n",
        "\n",
        "        dropout : float between 0 and 1\n",
        "            Whether to apply dropout to individual messages before they are\n",
        "            reduced to each incoming atom.\n",
        "\n",
        "        reducer : ['sum', 'mean', 'max', or 'min']\n",
        "            How to collect incoming messages for each atom. In this library,\n",
        "            I'm careful to only have messages be a function of the sending\n",
        "            atom, so we can sort the connectivity matrix by recieving atom.\n",
        "            That lets us use the `segment_*` methods from tensorflow, instead\n",
        "            of the `unsorted_segment_*` methods.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.reducer = reducer\n",
        "\n",
        "        reducer_dict = {\n",
        "            None: tf.segment_sum,\n",
        "            'sum': tf.segment_sum,\n",
        "            'mean': tf.segment_mean,\n",
        "            'max': tf.segment_max,\n",
        "            'min': tf.segment_min\n",
        "        }\n",
        "\n",
        "        self._reducer = reducer_dict[reducer]\n",
        "\n",
        "        super(MessageLayer, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\" Perform a single message passing step, returing the summed messages\n",
        "        for each recieving atom.\n",
        "\n",
        "        Inputs are [atom_matrix, bond_matrix, connectivity_matrix]\n",
        "\n",
        "        atom_matrix : (num_atoms_in_batch, d)\n",
        "            The input matrix of current hidden states for each atom\n",
        "\n",
        "        bond_matrix : (num_bonds_in_batch, d, d)\n",
        "            A matrix of current edge features, with each edge represented as a\n",
        "            (dxd) matrix.\n",
        "\n",
        "        connectivity : (num_bonds_in_batch, 2)\n",
        "            A matrix of (a_i, a_j) pairs that indicates the bond in bond_matrix\n",
        "            connecting atom_matrix[a_j] to atom_matrix[a_i].\n",
        "            The first entry indicates the recieving atom.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        atom_matrix, bond_matrix, connectivity = inputs\n",
        "\n",
        "        # Gather the atom matrix so that each reciever node corresponds with\n",
        "        # the given bond_matrix entry\n",
        "        atom_gathered = tf.gather(atom_matrix, connectivity[:, 1])\n",
        "\n",
        "        # Multiply the bond matrices by the gathered atom matrices\n",
        "        messages = K.batch_dot(bond_matrix, atom_gathered)\n",
        "\n",
        "        # Add dropout on a message-by-message basis if desired\n",
        "        def add_dropout():\n",
        "            if 0. < self.dropout < 1.:\n",
        "                return K.dropout(messages, self.dropout)\n",
        "            else:\n",
        "                return messages\n",
        "\n",
        "        dropout_messages = K.in_train_phase(\n",
        "            add_dropout(), messages, training=training)\n",
        "\n",
        "        # Sum each message along the (sorted) reciever nodes\n",
        "        summed_message = self._reducer(dropout_messages, connectivity[:, 0])\n",
        "\n",
        "        return summed_message\n",
        "\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Computes the shape of the output, which should be the same\n",
        "        dimension as the first input, that atom hidden state \"\"\"\n",
        "\n",
        "        assert input_shape and len(input_shape) == 3\n",
        "        assert input_shape[0][-1]  # atom hidden state dimension must be specified\n",
        "        return input_shape[0]\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'dropout': self.dropout,\n",
        "            'reducer': self.reducer,\n",
        "        }\n",
        "        base_config = super(MessageLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class GatherAtomToBond(Layer):\n",
        "    \"\"\" Reshapes the atom matrix (num_atoms_in_batch, d) to the bond matrix\n",
        "    (num_bonds_in_batch, d) by reindexing according to which atom is involved\n",
        "    in each bond.\n",
        "\n",
        "    index : 0 or 1\n",
        "        whether to gather the sending atoms (1) or recieving atoms (0) for each\n",
        "        bond.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, index, **kwargs):\n",
        "        self.index = index\n",
        "        super(GatherAtomToBond, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        atom_matrix, connectivity = inputs\n",
        "        return  tf.gather(atom_matrix, connectivity[:, self.index])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Computes the shape of the output,\n",
        "        which should be the shape of the atom matrix with the length\n",
        "        of the bond matrix \"\"\"\n",
        "\n",
        "        assert input_shape and len(input_shape) == 2\n",
        "        return input_shape[0]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'index': self.index,\n",
        "        }\n",
        "        base_config = super(GatherAtomToBond, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class Reducer(Layer):\n",
        "    \"\"\" Superclass for reducing methods.\n",
        "\n",
        "    reducer : ['sum', 'mean', 'max', or 'min']\n",
        "        How to collect elements for each atom or molecule. In this library,\n",
        "        I'm careful to only have messages be a function of the sending\n",
        "        atom, so we can sort the connectivity matrix by recieving atom.\n",
        "        That lets us use the `segment_*` methods from tensorflow, instead\n",
        "        of the `unsorted_segment_*` methods.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, reducer=None, **kwargs):\n",
        "\n",
        "        self.reducer = reducer\n",
        "\n",
        "        reducer_dict = {\n",
        "            None: tf.math.segment_sum,\n",
        "            'sum': tf.math.segment_sum,\n",
        "            'unsorted_sum': tf.math.unsorted_segment_sum,\n",
        "            'mean': tf.math.segment_mean,\n",
        "            'unsorted_mean': tf.math.unsorted_segment_mean,\n",
        "            'max': tf.math.segment_max,\n",
        "            'min': tf.math.segment_min\n",
        "        }\n",
        "\n",
        "        self._reducer = reducer_dict[reducer]\n",
        "\n",
        "        super(Reducer, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'reducer': self.reducer}\n",
        "        base_config = super(Reducer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert input_shape and len(input_shape) == 2\n",
        "        # Output shape is (n_graphs, atom_dim)\n",
        "        return input_shape[0]\n",
        "\n",
        "\n",
        "class ReduceAtomToMol(Reducer):\n",
        "    \"\"\" Sum over all atoms in each molecule.\n",
        "\n",
        "    Inputs\n",
        "\n",
        "    atom_matrix : (num_atoms_in_batch, d)\n",
        "        atom hidden states for each atom in the batch\n",
        "\n",
        "    node_graph_indices : (num_atoms_in_batch,)\n",
        "        A scalar for each atom representing which molecule in the batch the\n",
        "        atom belongs to. This is generated by the preprocessor class, and\n",
        "        essentially looks like [0, 0, 0, 1, 1] for a batch with a 3 atom\n",
        "        molecule and a 2 atom molecule.\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        atom_matrix, node_graph_indices = inputs\n",
        "        return self._reducer(atom_matrix, node_graph_indices)\n",
        "\n",
        "class ReduceBondToPro(Reducer):\n",
        "    \"\"\"\n",
        "    Sums over bonds acoording to bond_index to get target bond properties\n",
        "\n",
        "    Inputs\n",
        "\n",
        "    bond_matrix : (num_bonds_in_batch, d)\n",
        "        bond hidden states for each bond in the batch\n",
        "\n",
        "    bond_index : (bond_atoms_in_batch, )\n",
        "        A scalar for each bond representing which number in the target property\n",
        "        the bond links to. This is generated by the preprocessor class, and\n",
        "        essentially looks like [-1,-1,0,0,-1,-1,1....]\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        bond_matrix, bond_index, n_pro = inputs\n",
        "        num_segments = tf.reduce_sum(n_pro)\n",
        "        return self._reducer(bond_matrix, bond_index, num_segments)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert input_shape and len(input_shape) == 3\n",
        "        return input_shape[0]\n",
        "\n",
        "class ReduceAtomToPro(Reducer):\n",
        "    \"\"\"\n",
        "    Sums over atoms acoording to atom_index to get target atom properties\n",
        "\n",
        "    Inputs\n",
        "\n",
        "    atom_matrix : (num_atoms_in_batch, d)\n",
        "        atom hidden states for each atom in the batch\n",
        "\n",
        "    atom_index : (atom_atoms_in_batch, )\n",
        "        A scalar for each atom representing which number in the target property\n",
        "        the atom links to. This is generated by the preprocessor class, and\n",
        "        essentially looks like [-1,-1,0,0,-1,-1,1....]\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        atom_matrix, atom_index, n_pro = inputs\n",
        "        num_segments = tf.reduce_sum(n_pro)\n",
        "        return self._reducer(atom_matrix, atom_index, num_segments)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert input_shape and len(input_shape) == 3\n",
        "        return input_shape[0]\n",
        "\n",
        "class ReduceBondToAtom(Reducer):\n",
        "\n",
        "    \"\"\" Sums over the incoming messages from all sender atoms.\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    bond_matrix : (num_bonds_in_batch, d)\n",
        "        A matrix of messages coming from each sender atom; one row for each\n",
        "        bond/edge.\n",
        "\n",
        "    connectivity : (num_bonds_in_batch, 2)\n",
        "        A matrix of (a_i, a_j) pairs that indicates the bond in bond_matrix\n",
        "        connecting atom_matrix[a_j] to atom_matrix[a_i].\n",
        "        The first entry indicates the recieving atom.\n",
        "\n",
        "    Again, I'm careful to only have the messages be a function of the sending\n",
        "    node, such that we can use sorted methods in performing the reduction.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        bond_matrix, connectivity = inputs\n",
        "        return self._reducer(bond_matrix, connectivity[:, 0])\n",
        "\n",
        "\n",
        "class Squeeze(Layer):\n",
        "    \"\"\" Keras forces inputs to be a vector per entry, so this layer squeezes\n",
        "    them to a single dimension.\n",
        "\n",
        "    I.e., node_graph_indices will have shape (num_atoms_in_batch, 1), while its\n",
        "    easier to work with a vector of shape (num_atoms_in_batch,)\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return K.squeeze(inputs, 1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "\n",
        "class Embedding2D(Layer):\n",
        "    \"\"\" Keras typically wants to embed items as a single vector, while for the\n",
        "    matrix multiplication method of Gilmer 2017 we need a matrix for each bond\n",
        "    type. This just implements that fairly simple extension of the traditional\n",
        "    embedding layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim,\n",
        "                 embeddings_initializer='uniform',\n",
        "                 embeddings_regularizer=None,\n",
        "                 embeddings_constraint=None,\n",
        "                 **kwargs):\n",
        "\n",
        "        super(Embedding2D, self).__init__(**kwargs)\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embeddings_initializer = initializers.get(embeddings_initializer)\n",
        "        self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n",
        "        self.embeddings_constraint = constraints.get(embeddings_constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.embeddings = self.add_weight(\n",
        "            shape=(self.input_dim, self.output_dim, self.output_dim),\n",
        "            initializer=self.embeddings_initializer,\n",
        "            name='bond_embedding_weights',\n",
        "            regularizer=self.embeddings_regularizer,\n",
        "            constraint=self.embeddings_constraint)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.nn.embedding_lookup(self.embeddings, inputs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_dim, self.output_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'input_dim': self.input_dim,\n",
        "            'output_dim': self.output_dim,\n",
        "            'embeddings_initializer':\n",
        "            initializers.serialize(self.embeddings_initializer),\n",
        "            'embeddings_regularizer':\n",
        "            regularizers.serialize(self.embeddings_regularizer),\n",
        "            'embeddings_constraint':\n",
        "            constraints.serialize(self.embeddings_constraint),\n",
        "        }\n",
        "        base_config = super(Embedding2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class EdgeNetwork(Layer):\n",
        "    \"\"\" A layer to embed (bond_type, distance) pairs as a NxN matrix.\n",
        "\n",
        "    Inputs:\n",
        "    units : dimension of the output matrix\n",
        "    bond_classes : number of unique bonds\n",
        "\n",
        "    First perfoms a 1-hot encoding of the bond_type, then passes the\n",
        "    (*one_hot_encoding, distance) vector to a dense layer. This is the \"Edge\n",
        "    Network\" message described by Gilmer, 2017.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units, bond_classes,\n",
        "                 activation=None,\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "\n",
        "        super(EdgeNetwork, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.bond_classes = bond_classes\n",
        "\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.kernel = self.add_weight(shape=(self.bond_classes + 1, self.units**2),\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.units**2,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        bond_type, distance = inputs\n",
        "        bond_type_onehot = tf.one_hot(tf.squeeze(bond_type), self.bond_classes)\n",
        "        stacked_inputs = tf.concat([bond_type_onehot, distance], 1)\n",
        "\n",
        "        output = K.dot(stacked_inputs, self.kernel)\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "\n",
        "        output = tf.reshape(output, [-1, self.units, self.units])\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0][0], self.units, self.units)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'units': self.units,\n",
        "            'bond_classes': self.bond_classes,\n",
        "            'activation': activations.serialize(self.activation),\n",
        "            'use_bias': self.use_bias,\n",
        "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "            'activity_regularizer':\n",
        "                regularizers.serialize(self.activity_regularizer),\n",
        "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
        "        }\n",
        "        base_config = super(EdgeNetwork, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO44bbWPTpjd"
      },
      "outputs": [],
      "source": [
        "train_file = '/content/drive/MyDrive/CSC461/train.pkl.gz'\n",
        "test_file = '/content/drive/MyDrive/CSC461/test.pkl.gz'\n",
        "val_file = '/content/drive/MyDrive/CSC461/valid.pkl.gz'\n",
        "train = pd.read_pickle(train_file)\n",
        "test = pd.read_pickle(test_file)\n",
        "val = pd.read_pickle(val_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2ARmo4SWPF0",
        "outputId": "9d222a76-9028-41bf-f72a-fd073a0dbb7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.2862277,  1.8515768,  3.06077  ,  1.8287755,  2.1147938,\n",
              "        1.9405926,  2.4125774,  5.2048125,  1.7113038,  1.9827293,\n",
              "        1.6478252,  5.1483564,  9.646486 ,  6.1986713,  2.1315756,\n",
              "        2.0812304,  2.3436267,  1.7480594,  2.5291371,  1.9526317,\n",
              "        5.372994 ,  1.7547172,  1.7854533,  2.181191 , 11.188395 ,\n",
              "        6.192834 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "y_train = train.Shift.values\n",
        "y_test = test.Shift.values\n",
        "y_val = val.Shift.values\n",
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3V_g2ZsWQuS",
        "outputId": "ba3d0e2d-c798-4df0-c7a6-3409109a23f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_atom': 57,\n",
              " 'n_bond': 1274,\n",
              " 'n_pro': 26,\n",
              " 'atom': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 3, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]),\n",
              " 'bond': array([2, 3, 3, ..., 0, 0, 0]),\n",
              " 'distance': array([1.0817016, 1.3787208, 1.3937682, ..., 4.7569475, 4.868445 ,\n",
              "        4.896678 ], dtype=float32),\n",
              " 'connectivity': array([[ 0, 31],\n",
              "        [ 0,  5],\n",
              "        [ 0,  1],\n",
              "        ...,\n",
              "        [56, 53],\n",
              "        [56, 25],\n",
              "        [56, 54]]),\n",
              " 'atom_index': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,  2,\n",
              "         3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
              "        20, 21, 22, 23, 24, 25])}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "processed_inputs_path = '/content/drive/MyDrive/CSC461/processed_inputs.p'\n",
        "\n",
        "# Load the pickle file\n",
        "with open(processed_inputs_path, 'rb') as file:\n",
        "    processed_inputs = pickle.load(file)\n",
        "\n",
        "# Access the elements in the dictionary\n",
        "inputs_train = processed_inputs['inputs_train']\n",
        "inputs_valid = processed_inputs['inputs_valid']\n",
        "inputs_test = processed_inputs['inputs_test']\n",
        "preprocessor = processed_inputs['preprocessor']\n",
        "\n",
        "inputs_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67kRJ4mT4N6r"
      },
      "outputs": [],
      "source": [
        "with open(processed_inputs_path, 'rb') as f:\n",
        "    input_data = pickle.load(f)\n",
        "\n",
        "preprocessor = input_data['preprocessor']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More functions"
      ],
      "metadata": {
        "id": "nj3t2qmFnveC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Nm4lRNQ6ha5"
      },
      "outputs": [],
      "source": [
        "def rbf_expansion(distances, mu=0, delta=0.1, kmax=256):\n",
        "    k = np.arange(0, kmax)\n",
        "    logits = -(np.atleast_2d(distances).T - (-mu + delta * k))**2 / delta\n",
        "    return np.exp(logits)\n",
        "\n",
        "def atomic_number_tokenizer(atom):\n",
        "    return atom.GetNumRadicalElectrons()\n",
        "\n",
        "def _compute_stacked_offsets(sizes, repeats):\n",
        "    return np.repeat(np.cumsum(np.hstack([0, sizes[:-1]])), repeats)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "from keras.utils import Sequence\n",
        "\n",
        "class GraphSequence(Sequence):\n",
        "\n",
        "    def __init__(self, inputs, y=None, batch_size=1, shuffle=True,\n",
        "                 final_batch=True):\n",
        "        \"\"\" A keras.Sequence generator to be passed to model.fit_generator. (or\n",
        "        any other *_generator method.) Returns (inputs, y) tuples where\n",
        "        molecule feature matrices have been stitched together. Offsets the\n",
        "        connectivity matrices such that atoms are indexed appropriately.\n",
        "\n",
        "        batch_size: number of molecules per batch\n",
        "        shuffle : whether to shuffle the input data\n",
        "        final_batch : whether to include the final, incomplete batch\n",
        "\n",
        "        \"\"\"\n",
        "        self._inputs = inputs\n",
        "        self._y = np.asarray(y) if y is not None else None\n",
        "        self._input_keys = list(inputs[0].keys())\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.final_batch = final_batch\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Total number of batches \"\"\"\n",
        "        if self.final_batch:\n",
        "            return int(np.ceil(len(self._inputs) / float(self.batch_size)))\n",
        "        else:\n",
        "            return int(np.floor(len(self._inputs) / float(self.batch_size)))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            indices = np.arange(0, len(self._inputs))\n",
        "            np.random.shuffle(indices)\n",
        "            self._inputs = [self._inputs[i] for i in indices]\n",
        "            if self._y is not None:\n",
        "                self._y = self._y[indices]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" Calculate the feature matrices for a whole batch (with index `i` <\n",
        "        self.__len__). This involves adding offsets to the indices for each\n",
        "        atom in the connectivity matrix; such that atoms and bonds in later\n",
        "        molecules still refer to the correct atoms.\n",
        "\n",
        "        \"\"\"\n",
        "        batch_indexes = idx * self.batch_size + np.arange(0, self.batch_size)\n",
        "        batch_indexes = batch_indexes[batch_indexes < len(self._inputs)]\n",
        "\n",
        "        batch_data = {\n",
        "            key: self._concat([self._inputs[i][key] for i in batch_indexes])\n",
        "            for key in self._input_keys}\n",
        "\n",
        "        # Offset the connectivity matrix to account for the multiple graphs per\n",
        "        # batch\n",
        "        offset = _compute_stacked_offsets(\n",
        "            batch_data['n_atom'], batch_data['n_bond'])\n",
        "\n",
        "        batch_data['connectivity'] += offset[:, np.newaxis]\n",
        "\n",
        "        # Compute graph indices with shape (n_atom,) that indicate to which\n",
        "        # molecule each atom belongs.\n",
        "        n_graphs = len(batch_indexes)\n",
        "        batch_data['node_graph_indices'] = np.repeat(\n",
        "            np.arange(n_graphs), batch_data['n_atom'])\n",
        "\n",
        "        batch_data = self.process_data(batch_data)\n",
        "\n",
        "        # Keras takes to options, one (x, y) pairs, or just (x,) pairs if we're\n",
        "        # doing predictions. Here, if we've specified a y matrix, we return the\n",
        "        # x,y pairs for training, otherwise just return the x data.\n",
        "        if self._y is not None:\n",
        "            return (batch_data, np.concatenate(self._y[batch_indexes]).reshape(-1,1))\n",
        "\n",
        "        else:\n",
        "            return batch_data\n",
        "\n",
        "    def process_data(self, batch_data):\n",
        "        \"\"\" function to add additional processing to batch data before returning \"\"\"\n",
        "\n",
        "        # These aren't used currently, so I pop them. But we might need them at\n",
        "        # a later time.\n",
        "        del batch_data['n_atom']\n",
        "        del batch_data['n_bond']\n",
        "\n",
        "        return batch_data\n",
        "\n",
        "\n",
        "    def _concat(self, to_stack):\n",
        "        \"\"\" function to stack (or concatentate) depending on dimensions \"\"\"\n",
        "\n",
        "        if np.asarray(to_stack[0]).ndim >= 2:\n",
        "            return np.concatenate(to_stack)\n",
        "\n",
        "        else:\n",
        "            return np.hstack(to_stack)\n",
        "\n",
        "\n",
        "def _compute_stacked_offsets(sizes, repeats):\n",
        "    \"\"\" Computes offsets to add to indices of stacked np arrays.\n",
        "    When a set of np arrays are stacked, the indices of those from the second on\n",
        "    must be offset in order to be able to index into the stacked np array. This\n",
        "    computes those offsets.\n",
        "\n",
        "    Args:\n",
        "        sizes: A 1D sequence of np arrays of the sizes per graph.\n",
        "        repeats: A 1D sequence of np arrays of the number of repeats per graph.\n",
        "    Returns:\n",
        "        The index offset per graph.\n",
        "    \"\"\"\n",
        "    return np.repeat(np.cumsum(np.hstack([0, sizes[:-1]])), repeats)\n",
        "\n",
        "class RBFSequence(GraphSequence):\n",
        "    def process_data(self, batch_data):\n",
        "        batch_data['distance_rbf'] = rbf_expansion(batch_data['distance'])\n",
        "\n",
        "        offset = _compute_stacked_offsets(\n",
        "            batch_data['n_pro'], batch_data['n_atom'])\n",
        "\n",
        "        offset = np.where(batch_data['atom_index']>=0, offset, 0)\n",
        "        batch_data['atom_index'] += offset\n",
        "\n",
        "        del batch_data['n_atom']\n",
        "        del batch_data['n_bond']\n",
        "        del batch_data['distance']\n",
        "\n",
        "        return batch_data"
      ],
      "metadata": {
        "id": "R0vHYfHUn0we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "for row,y in zip(input_data['inputs_train'], y_train):\n",
        "    X.extend(row['atom'][row['atom_index']>=0])\n",
        "    Y.extend(y[row['atom_index'][row['atom_index']>=0]])"
      ],
      "metadata": {
        "id": "7JZ0yuQYoUmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atom_total = 0\n",
        "for mol in inputs_train:\n",
        "  atom_total += mol['n_pro']\n",
        "atom_total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW2gVTxhp9Sy",
        "outputId": "4b412415-f020-49b7-909c-85256e124c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102199"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data['inputs_train'][0]\n",
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kLYzN9NqEyF",
        "outputId": "a6cf9601-a509-4efc-d7bb-a003894fd97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.2862277,  1.8515768,  3.06077  ,  1.8287755,  2.1147938,\n",
              "        1.9405926,  2.4125774,  5.2048125,  1.7113038,  1.9827293,\n",
              "        1.6478252,  5.1483564,  9.646486 ,  6.1986713,  2.1315756,\n",
              "        2.0812304,  2.3436267,  1.7480594,  2.5291371,  1.9526317,\n",
              "        5.372994 ,  1.7547172,  1.7854533,  2.181191 , 11.188395 ,\n",
              "        6.192834 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Z0GuvVq1g_",
        "outputId": "90df9880-e334-43f0-a03a-af5990df504c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8515768"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxDZrrrMsbeb",
        "outputId": "2783a716-e567-4cbc-9f76-316535e3b3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFimL663sevi",
        "outputId": "96bee860-b74c-4515-93a7-945764dffd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_atom': 57,\n",
              " 'n_bond': 1274,\n",
              " 'n_pro': 26,\n",
              " 'atom': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 3, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]),\n",
              " 'bond': array([2, 3, 3, ..., 0, 0, 0]),\n",
              " 'distance': array([1.0817016, 1.3787208, 1.3937682, ..., 4.7569475, 4.868445 ,\n",
              "        4.896678 ], dtype=float32),\n",
              " 'connectivity': array([[ 0, 31],\n",
              "        [ 0,  5],\n",
              "        [ 0,  1],\n",
              "        ...,\n",
              "        [56, 53],\n",
              "        [56, 25],\n",
              "        [56, 54]]),\n",
              " 'atom_index': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,  2,\n",
              "         3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
              "        20, 21, 22, 23, 24, 25])}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atom_means = pd.DataFrame({'atom':X, 'shift':Y}).dropna().groupby('atom')['shift'].mean()"
      ],
      "metadata": {
        "id": "QPhHEqaGshW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atom_means = atom_means.reindex(np.arange(preprocessor.atom_classes)).fillna(0)\n",
        "atom_means"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "OjDQKKgss0EH",
        "outputId": "d21b3273-eea3-4d6f-b527-b5d91e25d7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "atom\n",
              "0    0.000000\n",
              "1    0.000000\n",
              "2    3.022405\n",
              "3    3.280265\n",
              "4    3.952668\n",
              "5    0.000000\n",
              "6    0.000000\n",
              "7    1.258198\n",
              "8    0.000000\n",
              "9    0.000000\n",
              "Name: shift, dtype: float32"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shift</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>atom</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.022405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.280265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.952668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.258198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float32</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'atom':X, 'shift':Y})['atom'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "skHK0k8ms1bt",
        "outputId": "1ac08fae-8915-48c6-b7e8-f1efaa979a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "atom\n",
              "4    102154\n",
              "2        31\n",
              "3        13\n",
              "7         1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>atom</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>102154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_sequence = RBFSequence(input_data['inputs_train'], y_train, batch_size)\n",
        "valid_sequence = RBFSequence(input_data['inputs_valid'], y_val, batch_size)"
      ],
      "metadata": {
        "id": "t87Mnm-is8Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(train_sequence)\n",
        "train_sequence.__class__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "YRPVY8mWxdxA",
        "outputId": "b52f8053-b9b8-45f6-8092-663bf156cc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.RBFSequence"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>RBFSequence</b><br/>def __init__(inputs, y=None, batch_size=1, shuffle=True, final_batch=True)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\"></a>Base class for defining a parallel dataset using Python code.\n",
              "\n",
              "Every `PyDataset` must implement the `__getitem__()` and the `__len__()`\n",
              "methods. If you want to modify your dataset between epochs,\n",
              "you may additionally implement `on_epoch_end()`,\n",
              "or `on_epoch_begin` to be called at the start of each epoch.\n",
              "The `__getitem__()` method should return a complete batch\n",
              "(not a single sample), and the `__len__` method should return\n",
              "the number of batches in the dataset (rather than the number of samples).\n",
              "\n",
              "Args:\n",
              "    workers: Number of workers to use in multithreading or\n",
              "        multiprocessing.\n",
              "    use_multiprocessing: Whether to use Python multiprocessing for\n",
              "        parallelism. Setting this to `True` means that your\n",
              "        dataset will be replicated in multiple forked processes.\n",
              "        This is necessary to gain compute-level (rather than I/O level)\n",
              "        benefits from parallelism. However it can only be set to\n",
              "        `True` if your dataset can be safely pickled.\n",
              "    max_queue_size: Maximum number of batches to keep in the queue\n",
              "        when iterating over the dataset in a multithreaded or\n",
              "        multipricessed setting.\n",
              "        Reduce this value to reduce the CPU memory consumption of\n",
              "        your dataset. Defaults to 10.\n",
              "\n",
              "Notes:\n",
              "\n",
              "- `PyDataset` is a safer way to do multiprocessing.\n",
              "    This structure guarantees that the model will only train\n",
              "    once on each sample per epoch, which is not the case\n",
              "    with Python generators.\n",
              "- The arguments `workers`, `use_multiprocessing`, and `max_queue_size`\n",
              "    exist to configure how `fit()` uses parallelism to iterate\n",
              "    over the dataset. They are not being used by the `PyDataset` class\n",
              "    directly. When you are manually iterating over a `PyDataset`,\n",
              "    no parallelism is applied.\n",
              "\n",
              "Example:\n",
              "\n",
              "```python\n",
              "from skimage.io import imread\n",
              "from skimage.transform import resize\n",
              "import numpy as np\n",
              "import math\n",
              "\n",
              "# Here, `x_set` is list of path to the images\n",
              "# and `y_set` are the associated classes.\n",
              "\n",
              "class CIFAR10PyDataset(keras.utils.PyDataset):\n",
              "\n",
              "    def __init__(self, x_set, y_set, batch_size, **kwargs):\n",
              "        super().__init__(**kwargs)\n",
              "        self.x, self.y = x_set, y_set\n",
              "        self.batch_size = batch_size\n",
              "\n",
              "    def __len__(self):\n",
              "        # Return number of batches.\n",
              "        return math.ceil(len(self.x) / self.batch_size)\n",
              "\n",
              "    def __getitem__(self, idx):\n",
              "        # Return x, y for batch idx.\n",
              "        low = idx * self.batch_size\n",
              "        # Cap upper bound at array length; the last batch may be smaller\n",
              "        # if the total number of items is not a multiple of batch size.\n",
              "        high = min(low + self.batch_size, len(self.x))\n",
              "        batch_x = self.x[low:high]\n",
              "        batch_y = self.y[low:high]\n",
              "\n",
              "        return np.array([\n",
              "            resize(imread(file_name), (200, 200))\n",
              "               for file_name in batch_x]), np.array(batch_y)\n",
              "```</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_data = input_data['inputs_train'][0]\n",
        "\n",
        "batch_data['distance_rbf'] = rbf_expansion(batch_data['distance'])\n",
        "# offset = _compute_stacked_offsets(batch_data['n_pro'], batch_data['n_atom'])\n",
        "# sizes = batch_data['n_atom']\n",
        "# repeats = batch_data['n_bond']\n",
        "# np.repeat(np.cumsum(np.hstack([0, sizes[:-1]])), repeats)\n",
        "batch_data"
      ],
      "metadata": {
        "id": "5CFxre_ixnXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e770127-5ef3-42fd-94d3-1283aa148d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_atom': 57,\n",
              " 'n_bond': 1274,\n",
              " 'n_pro': 26,\n",
              " 'atom': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 3, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]),\n",
              " 'bond': array([2, 3, 3, ..., 0, 0, 0]),\n",
              " 'distance': array([1.0817016, 1.3787208, 1.3937682, ..., 4.7569475, 4.868445 ,\n",
              "        4.896678 ], dtype=float32),\n",
              " 'connectivity': array([[ 0, 31],\n",
              "        [ 0,  5],\n",
              "        [ 0,  1],\n",
              "        ...,\n",
              "        [56, 53],\n",
              "        [56, 25],\n",
              "        [56, 54]]),\n",
              " 'atom_index': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,  2,\n",
              "         3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
              "        20, 21, 22, 23, 24, 25]),\n",
              " 'distance_rbf': array([[8.28731687e-006, 6.52437027e-005, 4.20537142e-004, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [5.55421160e-009, 7.92017194e-008, 9.24672414e-007, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [3.65965223e-009, 5.37801536e-008, 6.47061206e-007, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        ...,\n",
              "        [5.31443856e-099, 6.51418454e-095, 6.53738148e-091, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [1.16033091e-103, 1.77758321e-099, 2.22955979e-095, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [7.36606217e-105, 1.19400564e-100, 1.58459571e-096, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000]])}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sequence[2][0]['n_pro'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyh518xlGlJG",
        "outputId": "a86deae2-4d2e-4f7e-95f6-a157da9ee054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "7hHCVeD1cQXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequence[2][0]"
      ],
      "metadata": {
        "id": "fML0nq9iGo7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24dc892-6a55-45cf-df24-126ce1dcf948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_pro': array([23, 33, 22, 24, 16, 20, 20, 29, 31,  4, 26, 21, 30, 20, 22, 22, 21,\n",
              "         7, 13, 28, 39, 20, 36, 11, 24, 18, 14, 30, 40, 16, 27, 44]),\n",
              " 'atom': array([2, 2, 2, ..., 4, 4, 4]),\n",
              " 'bond': array([2, 2, 2, ..., 0, 0, 0]),\n",
              " 'connectivity': array([[   0,   22],\n",
              "        [   0,   23],\n",
              "        [   0,   24],\n",
              "        ...,\n",
              "        [1500, 1445],\n",
              "        [1500, 1492],\n",
              "        [1500, 1447]]),\n",
              " 'atom_index': array([ -1,  -1,  -1, ..., 748, 749, 750]),\n",
              " 'node_graph_indices': array([ 0,  0,  0, ..., 31, 31, 31]),\n",
              " 'distance_rbf': array([[7.14868225e-006, 5.70513607e-005, 3.72775296e-004, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [6.49087834e-006, 5.22621210e-005, 3.44517825e-004, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [6.45558713e-006, 5.20039009e-005, 3.42986638e-004, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        ...,\n",
              "        [1.92554872e-098, 2.29713828e-094, 2.24367976e-090, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [1.74600082e-099, 2.19077055e-095, 2.25055924e-091, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [3.66879193e-106, 6.32143086e-102, 8.91761679e-098, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000]])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "maYTp0a2cTtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atom_index = Input(shape=(1,), name='atom_index', dtype='int32')\n",
        "atom_types = Input(shape=(1,), name='atom', dtype='int32')\n",
        "distance_rbf = Input(shape=(256,), name='distance_rbf', dtype='float32')\n",
        "connectivity = Input(shape=(2,), name='connectivity', dtype='int32')\n",
        "n_pro = Input(shape=(1,), name='n_pro', dtype='int32')"
      ],
      "metadata": {
        "id": "ODp2qXCOuH9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atom_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDNvGfOs1s03",
        "outputId": "f7925842-c432-4ba8-8792-437d471d0cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor shape=(None, 1), dtype=int32, sparse=False, name=atom_index>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "j2uR6hlOcWac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squeeze = Squeeze()\n",
        "\n",
        "satom_index = squeeze(atom_index)\n",
        "satom_types = squeeze(atom_types)\n",
        "sn_pro = squeeze(n_pro)\n",
        "# Initialize RNN and MessageLayer instances\n",
        "atom_features = 256\n",
        "\n",
        "# Initialize the atom states\n",
        "atom_state = Embedding(\n",
        "    preprocessor.atom_classes,\n",
        "    atom_features, name='atom_embedding')(satom_types)\n",
        "\n",
        "atomwise_shift = Embedding(\n",
        "    preprocessor.atom_classes, 1, name='atomwise_shift',\n",
        "    embeddings_initializer=keras.initializers.constant(atom_means.values)\n",
        ")(satom_types)\n",
        "\n",
        "bond_state = distance_rbf"
      ],
      "metadata": {
        "id": "2cC3mCYn48_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "ClW8nxh9cYH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def message_block(atom_state, bond_state, connectivity):\n",
        "\n",
        "    atom_state = Dense(atom_features, use_bias=False)(atom_state)\n",
        "\n",
        "    source_atom_gather = GatherAtomToBond(1)\n",
        "    target_atom_gather = GatherAtomToBond(0)\n",
        "\n",
        "    source_atom = source_atom_gather([atom_state, connectivity])\n",
        "    target_atom = target_atom_gather([atom_state, connectivity])\n",
        "\n",
        "    # Edge update network\n",
        "    bond_state_message = Concatenate()([source_atom, target_atom, bond_state])\n",
        "    bond_state_message = Dense(2*atom_features, activation='softplus')(bond_state_message)\n",
        "    bond_state_message = Dense(atom_features)(bond_state_message)\n",
        "\n",
        "    bond_state_message = Dense(atom_features, activation='softplus')(bond_state_message)\n",
        "    bond_state_message = Dense(atom_features, activation='softplus')(bond_state_message)\n",
        "    bond_state = Add()([bond_state_message, bond_state])\n",
        "\n",
        "    # message function\n",
        "    messages = Multiply()([source_atom, bond_state])\n",
        "    messages = ReduceBondToAtom(reducer='sum')([messages, connectivity])\n",
        "\n",
        "    # state transition function\n",
        "    messages = Dense(atom_features, activation='softplus')(messages)\n",
        "    messages = Dense(atom_features)(messages)\n",
        "    atom_state = Add()([atom_state, messages])\n",
        "\n",
        "    return atom_state, bond_state"
      ],
      "metadata": {
        "id": "__MNsp1Q587O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bond_state"
      ],
      "metadata": {
        "id": "zIrdpC596IAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329f27c5-19c9-4305-f60c-97ae6f541e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor shape=(None, 256), dtype=float32, sparse=False, name=distance_rbf>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "AVUqI6g7cdJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "    atom_state, bond_state = message_block(atom_state, bond_state, connectivity)"
      ],
      "metadata": {
        "id": "83nRXHg27_ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Going through test forward pass of message passing in the CASCADE model"
      ],
      "metadata": {
        "id": "HlDq_wBLPeKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT (INSPECTION OF MESSAGE BLOCK FUNCTION)"
      ],
      "metadata": {
        "id": "Nid7LPsTcfDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Keras Embedding Layer to see whats happening (go from atom label to 256 vector)\n",
        "test_atom_state = Embedding(\n",
        "    preprocessor.atom_classes,\n",
        "    atom_features, name='atom_embedding')\n",
        "model = keras.Sequential()\n",
        "model.add(test_atom_state)\n",
        "input = np.array([2,2])\n",
        "test_atom_vectors = model.predict(input)\n",
        "#Defining connectivity, bond state for a simple one connection molecule\n",
        "test_connectivity = tf.convert_to_tensor(np.array(([0,1],[1,0])))\n",
        "test_bond_state = rbf_expansion(np.array([5,5]))\n",
        "#One Dense layer is run on the atoms initially\n",
        "test_atom_vectors = Dense(atom_features, use_bias=False)(test_atom_vectors)\n",
        "#Gather target and source atoms for messaging\n",
        "gather_thingy = GatherAtomToBond(0)\n",
        "other_gather_thingy = GatherAtomToBond(1)\n",
        "target_atoms = gather_thingy(inputs = [test_atom_vectors,test_connectivity])\n",
        "source_atoms = other_gather_thingy(inputs = [test_atom_vectors,test_connectivity])\n",
        "#Concatenates target, source and bond vectors into one long vector (3*256 in this case)\n",
        "bond_message = Concatenate()([target_atoms, source_atoms, test_bond_state])\n",
        "#Dense layer to 512 length vector\n",
        "bond_message = Dense(2*atom_features, activation='softplus')(bond_message)\n",
        "#Dense layer back to 256 length vector\n",
        "bond_message = Dense(atom_features)(bond_message)\n",
        "# Adding the message to the existing bond value and getting updated value\n",
        "test_bond_state = Add()([bond_message, test_bond_state])\n",
        "# Working on updating nodes, starting with element wise multiplication of the source atoms and the edges\n",
        "node_message = Multiply()([source_atoms, test_bond_state])\n",
        "# Adds all bonds connecting a single atom together\n",
        "node_message = ReduceBondToAtom(reducer='sum')([node_message, connectivity])\n",
        "# Two dense layers\n",
        "node_message = Dense(atom_features, activation='softplus')(node_message)\n",
        "node_message = Dense(atom_features)(node_message)\n",
        "# Adding the node messages to get the final node values\n",
        "final_atom_vectors = Add()([atom_state, node_message])\n",
        "final_atom_vectors.shape"
      ],
      "metadata": {
        "id": "4cAXTrrHQFvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468c99b0-4df9-437e-f15f-058672f95d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "TONqqVuV9Jqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atom_state = ReduceAtomToPro(reducer='unsorted_mean')([atom_state, satom_index, sn_pro])\n",
        "atomwise_shift = ReduceAtomToPro(reducer='unsorted_mean')([atomwise_shift, satom_index, sn_pro])\n",
        "\n",
        "atom_state = Dense(atom_features, activation='softplus')(atom_state)\n",
        "atom_state = Dense(atom_features, activation='softplus')(atom_state)\n",
        "atom_state = Dense(atom_features//2, activation='softplus')(atom_state)\n",
        "atom_state = Dense(1)(atom_state)\n",
        "\n",
        "output = Add()([atom_state, atomwise_shift])\n"
      ],
      "metadata": {
        "id": "qckQnwi38Lyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atom_index"
      ],
      "metadata": {
        "id": "VhuwA5wkG-QP",
        "outputId": "25074cc5-b1f4-4ac7-cf05-1e1688960d22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor shape=(None, 1), dtype=int32, sparse=False, name=atom_index>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "T3zg1FLbcv5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 5E-4\n",
        "epochs = 1200\n",
        "\n",
        "model = GraphModel([\n",
        "        atom_index, atom_types, distance_rbf, connectivity, n_pro], [atom_index])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss='mae')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "f4W7Q-KB8Tjj",
        "outputId": "f3937bdb-6f7f-456c-a26a-83dea275327d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"graph_model_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"graph_model_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ atom (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ distance_rbf (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ connectivity (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ n_pro (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ atom_index (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ atom (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ distance_rbf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ connectivity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ n_pro (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ atom_index (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "PQ2Syo-TcyrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decay_fn(epoch, learning_rate):\n",
        "    \"\"\" Jorgensen decays to 0.96*lr every 100,000 batches, which is approx\n",
        "    every 28 epochs \"\"\"\n",
        "    if (epoch % 70) == 0:\n",
        "        return 0.96 * learning_rate\n",
        "    else:\n",
        "        return learning_rate\n",
        "\n",
        "lr_decay = LearningRateScheduler(decay_fn)"
      ],
      "metadata": {
        "id": "hjrBuqqt8cTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT"
      ],
      "metadata": {
        "id": "kH6hYdbBc2hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/MyDrive/CSC461/best_model.keras\"\n",
        "csv_logger = CSVLogger('/content/drive/MyDrive/CSC461/log.csv')\n",
        "checkpoint = ModelCheckpoint(filepath, save_best_only=True, save_freq='epoch', verbose=1)\n",
        "hist = model.fit(train_sequence, validation_data=valid_sequence,\n",
        "                           epochs=epochs, verbose=1,\n",
        "                           callbacks=[checkpoint, csv_logger, lr_decay])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "cnogPwEG95OY",
        "outputId": "99cd5676-c707-4aa6-cbf1-afcddf477682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling GraphModel.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"graph_model_2_1/Cast_2:0\", shape=(None,), dtype=float32). Expected shape (None, 256), but input has incompatible shape (None,)\u001b[0m\n\nArguments received by GraphModel.call():\n  • inputs={'n_pro': 'tf.Tensor(shape=(None,), dtype=int64)', 'atom': 'tf.Tensor(shape=(None,), dtype=int64)', 'bond': 'tf.Tensor(shape=(None,), dtype=int64)', 'connectivity': 'tf.Tensor(shape=(None, 2), dtype=int64)', 'atom_index': 'tf.Tensor(shape=(None,), dtype=int64)', 'node_graph_indices': 'tf.Tensor(shape=(None,), dtype=int64)', 'distance_rbf': 'tf.Tensor(shape=(None, 256), dtype=float64)'}\n  • training=True\n  • mask={'n_pro': 'None', 'atom': 'None', 'bond': 'None', 'connectivity': 'None', 'atom_index': 'None', 'node_graph_indices': 'None', 'distance_rbf': 'None'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-8f203b091783>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcsv_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/CSC461/log.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m hist = model.fit(train_sequence, validation_data=valid_sequence,\n\u001b[0m\u001b[1;32m      5\u001b[0m                            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                            callbacks=[checkpoint, csv_logger, lr_decay])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling GraphModel.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"graph_model_2_1/Cast_2:0\", shape=(None,), dtype=float32). Expected shape (None, 256), but input has incompatible shape (None,)\u001b[0m\n\nArguments received by GraphModel.call():\n  • inputs={'n_pro': 'tf.Tensor(shape=(None,), dtype=int64)', 'atom': 'tf.Tensor(shape=(None,), dtype=int64)', 'bond': 'tf.Tensor(shape=(None,), dtype=int64)', 'connectivity': 'tf.Tensor(shape=(None, 2), dtype=int64)', 'atom_index': 'tf.Tensor(shape=(None,), dtype=int64)', 'node_graph_indices': 'tf.Tensor(shape=(None,), dtype=int64)', 'distance_rbf': 'tf.Tensor(shape=(None, 256), dtype=float64)'}\n  • training=True\n  • mask={'n_pro': 'None', 'atom': 'None', 'bond': 'None', 'connectivity': 'None', 'atom_index': 'None', 'node_graph_indices': 'None', 'distance_rbf': 'None'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_sequence[0][0]['distance_rbf'].shape"
      ],
      "metadata": {
        "id": "Rn0HUAsP-Fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4b6edd-135a-48fe-9f59-9f54fbd84e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16770, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_mod = keras.Sequential()\n",
        "test_mod.add(Input(shape=(256,), name='distance_rbf', dtype='float32'))\n",
        "test_mod.add(Dense(256, activation='softplus'))\n",
        "test_mod.summary()\n",
        "test_mod.predict(train_sequence[0][0]['distance_rbf'])"
      ],
      "metadata": {
        "id": "anxuJ1x7GFzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "747d7f79-51c8-488f-95b5-7bd2944a8cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,792\u001b[0m (257.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> (257.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,792\u001b[0m (257.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> (257.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.75749016, 0.57033974, 0.67821103, ..., 0.66581386, 0.7193932 ,\n",
              "        0.80530006],\n",
              "       [0.7468433 , 0.56934005, 0.6820942 , ..., 0.63832223, 0.77921623,\n",
              "        0.79469776],\n",
              "       [0.7437823 , 0.57471913, 0.6855024 , ..., 0.64088094, 0.78454655,\n",
              "        0.79514563],\n",
              "       ...,\n",
              "       [0.6949312 , 0.6935917 , 0.6204102 , ..., 0.6970189 , 0.6164915 ,\n",
              "        0.6758731 ],\n",
              "       [0.68610764, 0.6947843 , 0.6158033 , ..., 0.70515215, 0.6292391 ,\n",
              "        0.6921318 ],\n",
              "       [0.6856468 , 0.6948941 , 0.61546797, ..., 0.7058479 , 0.63004595,\n",
              "        0.69348747]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequence[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "lUi0daTXPvUi",
        "outputId": "e507e397-78da-4a52-e311-39dcb7278ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_sequence' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4904531d5e8a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_sequence' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AsMl6VHeSVmd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}